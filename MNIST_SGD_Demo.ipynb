{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digit Classification with SGD\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. Loading the MNIST dataset from sklearn\n",
    "2. Training an SGD classifier\n",
    "3. Generating confusion matrices for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset (this may take a moment the first time)\n",
    "print(\"Loading MNIST dataset...\")\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False, parser='auto')\n",
    "\n",
    "# Extract features and labels\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "\n",
    "# Convert labels to integers\n",
    "y = y.astype(np.uint8)\n",
    "\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Labels shape: {y.shape}\")\n",
    "print(f\"Feature range: {X.min()} to {X.max()}\")\n",
    "print(f\"Unique labels: {np.unique(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at a few sample digits\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    # Reshape the 784 features back to 28x28 image\n",
    "    digit_image = X[i].reshape(28, 28)\n",
    "    ax.imshow(digit_image, cmap='gray')\n",
    "    ax.set_title(f'Label: {y[i]}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Sample MNIST Digits', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proper train/dev/test split following ML best practices\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First split: separate test set (MNIST convention: last 10k samples)\n",
    "X_temp, X_test = X[:60000], X[60000:]\n",
    "y_temp, y_test = y[:60000], y[60000:]\n",
    "\n",
    "# Second split: divide remaining data into train/dev (80%/20%)\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.2, random_state=42, stratify=y_temp)\n",
    "\n",
    "print(f\"Training set: {X_train.shape} features, {y_train.shape} labels\")\n",
    "print(f\"Development set: {X_dev.shape} features, {y_dev.shape} labels\")\n",
    "print(f\"Test set: {X_test.shape} features, {y_test.shape} labels\")\n",
    "print(f\"\\nSplit percentages:\")\n",
    "total = len(X)\n",
    "print(f\"Train: {len(X_train)/total*100:.1f}%\")\n",
    "print(f\"Dev: {len(X_dev)/total*100:.1f}%\")\n",
    "print(f\"Test: {len(X_test)/total*100:.1f}%\")\n",
    "\n",
    "# Check class distribution in training set\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(\"\\nTraining set class distribution:\")\n",
    "for digit, count in zip(unique, counts):\n",
    "    print(f\"Digit {digit}: {count} samples ({count/len(y_train)*100:.1f}%)\")\n",
    "\n",
    "# Verify stratification worked (dev set should have similar distribution)\n",
    "unique_dev, counts_dev = np.unique(y_dev, return_counts=True)\n",
    "print(\"\\nDevelopment set class distribution:\")\n",
    "for digit, count in zip(unique_dev, counts_dev):\n",
    "    print(f\"Digit {digit}: {count} samples ({count/len(y_dev)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train SGD classifier\n",
    "print(\"Training SGD Classifier...\")\n",
    "sgd_clf = SGDClassifier(random_state=42, max_iter=1000, tol=1e-3)\n",
    "\n",
    "# Train the classifier\n",
    "sgd_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training completed!\")\n",
    "print(f\"Model classes: {sgd_clf.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate using cross-validation on training set\n",
    "print(\"Performing 3-fold cross-validation...\")\n",
    "cv_scores = cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean CV accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions using cross-validation to avoid overfitting\n",
    "print(\"Getting cross-validated predictions...\")\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train, cv=3)\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_mx = confusion_matrix(y_train, y_train_pred)\n",
    "print(\"Confusion matrix shape:\", conf_mx.shape)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confusion matrix with matplotlib\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(conf_mx, interpolation='nearest', cmap='Blues')\n",
    "plt.title('Confusion Matrix - MNIST SGD Classifier', fontsize=16)\n",
    "plt.colorbar()\n",
    "\n",
    "# Add labels\n",
    "tick_marks = np.arange(10)\n",
    "plt.xticks(tick_marks, range(10))\n",
    "plt.yticks(tick_marks, range(10))\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "\n",
    "# Add text annotations\n",
    "thresh = conf_mx.max() / 2.\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        plt.text(j, i, format(conf_mx[i, j], 'd'),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if conf_mx[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Use sklearn's ConfusionMatrixDisplay (cleaner)\n",
    "plt.figure(figsize=(10, 8))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_mx, display_labels=range(10))\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title('Confusion Matrix - MNIST SGD Classifier (sklearn version)', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze error rates per digit\n",
    "# Normalize confusion matrix to show error rates\n",
    "row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
    "norm_conf_mx = conf_mx / row_sums\n",
    "\n",
    "# Zero out the diagonal to focus on errors\n",
    "np.fill_diagonal(norm_conf_mx, 0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(norm_conf_mx, interpolation='nearest', cmap='Reds')\n",
    "plt.title('Confusion Matrix - Error Rates Only (Normalized)', fontsize=16)\n",
    "plt.colorbar()\n",
    "plt.xticks(range(10))\n",
    "plt.yticks(range(10))\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nMost common misclassifications:\")\n",
    "# Find the highest error rates (excluding diagonal)\n",
    "error_indices = np.unravel_index(np.argsort(norm_conf_mx.ravel())[-5:], norm_conf_mx.shape)\n",
    "for i in range(4, -1, -1):  # Show top 5 errors in descending order\n",
    "    true_digit = error_indices[0][i]\n",
    "    pred_digit = error_indices[1][i]\n",
    "    error_rate = norm_conf_mx[true_digit, pred_digit]\n",
    "    if error_rate > 0:  # Only show actual errors\n",
    "        print(f\"Digit {true_digit} classified as {pred_digit}: {error_rate:.3f} ({error_rate*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate detailed classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, evaluate on the test set\n",
    "print(\"Evaluating on test set...\")\n",
    "test_score = sgd_clf.score(X_test, y_test)\n",
    "print(f\"Test set accuracy: {test_score:.4f}\")\n",
    "\n",
    "# Generate test set predictions and confusion matrix\n",
    "y_test_pred = sgd_clf.predict(X_test)\n",
    "test_conf_mx = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=test_conf_mx, display_labels=range(10))\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title('Test Set Confusion Matrix - MNIST SGD Classifier', fontsize=14)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
